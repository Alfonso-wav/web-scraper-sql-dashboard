# Flujo Completo de Scraping desde el Frontend

## ðŸŽ¯ Nuevo Flujo Automatizado

Ahora puedes hacer **todo desde el frontend web**:

### 1ï¸âƒ£ Iniciar Scraping
En http://localhost:5000 encontrarÃ¡s un campo de bÃºsqueda en la parte superior:

```
ðŸ” Scraper de Amazon
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ cafe descafeinado                      [ðŸš€ Iniciar Scraping] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2ï¸âƒ£ Proceso AutomÃ¡tico
Al hacer clic en "Iniciar Scraping":

1. **Scraping** (5-10 min):
   - Ejecuta `python main.py "tu_termino"`
   - Visita Amazon.es y extrae 50 productos
   - Guarda en `data/extractions/amazon/amazon_tu_termino.json`

2. **Carga a DB** (automÃ¡tico):
   - Ejecuta `python load_dynamic_tables.py`
   - Crea tabla `amazon_tu_termino` 
   - Infiere columnas del JSON
   - Datos anidados â†’ tipo JSONB

3. **ActualizaciÃ³n Frontend**:
   - Recarga panel de tablas cada 30 segundos
   - Nueva tabla aparece automÃ¡ticamente
   - Puedes consultarla inmediatamente

### 3ï¸âƒ£ Consultar Datos
Una vez completado el proceso:

- **Panel derecho**: Ver nueva tabla y su esquema
- **Editor SQL**: Consultar los datos
- **Consultas ejemplo**: Adaptables a tu nueva tabla

## ðŸ“Š Ejemplo de Uso Completo

### Paso 1: Buscar productos
```
TÃ©rmino: "teclado mecanico"
[ðŸš€ Iniciar Scraping]

ðŸ”„ Scraping iniciado para "teclado mecanico"
â±ï¸ Esto puede tardar 5-10 minutos...
```

### Paso 2: Esperar (puedes seguir usando SQL)
```
âœ… Scraping completado
ðŸ”„ Cargando datos a PostgreSQL...
```

### Paso 3: Nueva tabla disponible
```
ðŸ—„ï¸ Tablas Disponibles
  ðŸ“‹ amazon_cafe
  ðŸ“‹ amazon_leche_de_vaca
  ðŸ“‹ amazon_monitor_gaming
  ðŸ“‹ amazon_teclado_mecanico  â† NUEVA
```

### Paso 4: Consultar
```sql
SELECT title, brand, price, rating 
FROM amazon_teclado_mecanico 
WHERE has_prime = true
ORDER BY rating DESC
LIMIT 10;
```

## ðŸ”§ Arquitectura del Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              FRONTEND (localhost:5000)               â”‚
â”‚                                                      â”‚
â”‚  [Input: tÃ©rmino bÃºsqueda] â†’ [ðŸš€ Iniciar Scraping] â”‚
â”‚                        â†“                             â”‚
â”‚              POST /scrape endpoint                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              BACKEND (Flask + Threading)             â”‚
â”‚                                                      â”‚
â”‚  Thread 1: main.py "tÃ©rmino"                        â”‚
â”‚    â”œâ”€ Playwright abre Chrome                        â”‚
â”‚    â”œâ”€ Busca en Amazon.es                            â”‚
â”‚    â”œâ”€ Extrae 50 productos                           â”‚
â”‚    â””â”€ Guarda JSON                                   â”‚
â”‚                        â†“                             â”‚
â”‚  Thread 2: load_dynamic_tables.py                   â”‚
â”‚    â”œâ”€ Lee JSON                                      â”‚
â”‚    â”œâ”€ Infiere esquema                               â”‚
â”‚    â”œâ”€ CREATE TABLE                                  â”‚
â”‚    â””â”€ INSERT datos                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           PostgreSQL (puerto 5434)                   â”‚
â”‚                                                      â”‚
â”‚  â€¢ amazon_cafe                                      â”‚
â”‚  â€¢ amazon_leche_de_vaca                             â”‚
â”‚  â€¢ amazon_monitor_gaming                            â”‚
â”‚  â€¢ amazon_[tu_termino] â† NUEVA TABLA                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## âš¡ CaracterÃ­sticas TÃ©cnicas

### Frontend (templates/sql_query.html)
- Input para tÃ©rmino de bÃºsqueda
- BotÃ³n que llama `startScraping()`
- Status en tiempo real (loading/success/error)
- Auto-reload de tablas cada 30 segundos

### Backend (sql_frontend.py)
- **Endpoint `/scrape`**: Recibe tÃ©rmino, lanza threads
- **Threading**: Proceso no bloquea el servidor
- **Timeout**: 10 minutos mÃ¡ximo por scraping
- **Auto-carga**: Llama a `load_dynamic_tables.py` automÃ¡ticamente

### Scraper (main.py)
- **Args CLI**: `python main.py "tÃ©rmino"` 
- **Modo detallado**: Activado por defecto desde API
- **Sin interacciÃ³n**: No pide confirmaciones
- **Output**: `data/extractions/amazon/amazon_tÃ©rmino.json`

### Cargador (load_dynamic_tables.py)
- **DinÃ¡mico**: Lee todos los JSON en carpeta
- **Inferencia**: Detecta tipos de columnas automÃ¡ticamente
- **JSONB**: Datos anidados se almacenan consultables
- **Idempotente**: Recrea tablas (DROP + CREATE)

## ðŸŽ® Tips de Uso

1. **MÃºltiples bÃºsquedas simultÃ¡neas**: El sistema usa threading, puedes lanzar varias bÃºsquedas (aunque no recomendado por carga)

2. **Monitoreo**: MantÃ©n el panel de tablas visible para ver cuÃ¡ndo aparece la nueva tabla

3. **SQL mientras esperas**: Puedes consultar otras tablas mientras el scraping corre en background

4. **Nombres de tabla**: Se limpian automÃ¡ticamente
   - `"cafÃ© orgÃ¡nico"` â†’ `amazon_cafe_organico`
   - `"monitor 4K"` â†’ `amazon_monitor_4k`

5. **Datos JSONB**: Consulta datos anidados
   ```sql
   SELECT title, specifications->>'TamaÃ±o' 
   FROM amazon_tu_tabla;
   ```

## ðŸ› Troubleshooting

**"No aparece la tabla"**
- Espera 10 minutos (scraping es lento)
- Verifica que haya JSON en `data/extractions/amazon/`
- Ejecuta manualmente: `python load_dynamic_tables.py`

**"Error en scraping"**
- Amazon puede bloquear: usa VPN o espera
- Chromium no instalado: `playwright install`
- Red lenta: aumenta timeout en main.py

**"BotÃ³n deshabilitado"**
- Hay un scraping en curso
- Espera o recarga la pÃ¡gina

## ðŸ“ CÃ³digo Clave

### Frontend - Iniciar Scraping
```javascript
async function startScraping() {
    const searchTerm = document.getElementById('searchTermInput').value;
    
    const response = await fetch('/scrape', {
        method: 'POST',
        headers: {'Content-Type': 'application/json'},
        body: JSON.stringify({ search_term: searchTerm })
    });
    
    // Auto-reload tablas cada 30 segundos
    setInterval(() => loadTables(), 30000);
}
```

### Backend - Endpoint Scraping
```python
@app.route('/scrape', methods=['POST'])
def start_scraping():
    search_term = request.get_json().get('search_term')
    
    def run_scraper():
        # Scraping
        subprocess.run(['.venv/bin/python', 'main.py', search_term])
        # Auto-carga
        subprocess.run(['.venv/bin/python', 'load_dynamic_tables.py'])
    
    thread = threading.Thread(target=run_scraper)
    thread.daemon = True
    thread.start()
    
    return jsonify({'success': True})
```

## ðŸš€ Mejoras Futuras Posibles

- âœ… Progreso en tiempo real (WebSocket)
- âœ… Cola de trabajos (mÃºltiples scraping)
- âœ… CachÃ© de resultados
- âœ… Notificaciones cuando termina
- âœ… Exportar a CSV/Excel desde frontend
- âœ… GrÃ¡ficos y visualizaciones
- âœ… ComparaciÃ³n entre tablas
