# Amazon Scraper con Playwright

Sistema completo de scraping de Amazon.es con an√°lisis de datos y frontend SQL **integrado**.

## üöÄ Caracter√≠sticas

- **Scraping desde el Frontend**: Inicia b√∫squedas directamente desde la interfaz web
- **Proceso autom√°tico**: Scraping ‚Üí JSON ‚Üí PostgreSQL sin intervenci√≥n manual
- **Datos detallados**: T√≠tulo, precio, marca, valoraciones, especificaciones, informaci√≥n nutricional
- **Base de datos din√°mica**: Cada b√∫squeda crea autom√°ticamente su tabla en PostgreSQL
- **Frontend SQL completo**: Interfaz web para scraping, consultas y visualizaci√≥n

## ‚ú® Flujo Completo End-to-End

```
üåê Frontend (http://localhost:5000)
    ‚Üì [Usuario introduce: "teclado mecanico"]
    ‚Üì [Click: üöÄ Iniciar Scraping]
    ‚Üì
ü§ñ Scraper (main.py)
    ‚Üì Visita Amazon.es
    ‚Üì Extrae 50 productos con detalles
    ‚Üì Guarda: data/extractions/amazon/amazon_teclado_mecanico.json
    ‚Üì
üíæ Cargador (load_dynamic_tables.py)
    ‚Üì Lee JSON
    ‚Üì Infiere esquema (columnas + tipos)
    ‚Üì CREATE TABLE amazon_teclado_mecanico
    ‚Üì INSERT 50 productos
    ‚Üì
üóÑÔ∏è PostgreSQL (puerto 5434)
    ‚Üì Nueva tabla disponible
    ‚Üì
üåê Frontend
    ‚Üì Auto-actualiza panel de tablas
    ‚úÖ ¬°Lista para consultar con SQL!
```

## üìã Estructura del Proyecto

```
scrapper_amazon/
‚îú‚îÄ‚îÄ main.py                      # Scraper principal con Playwright
‚îú‚îÄ‚îÄ load_dynamic_tables.py       # Carga JSON ‚Üí PostgreSQL (din√°mico)
‚îú‚îÄ‚îÄ sql_frontend.py              # Frontend web Flask para SQL
‚îú‚îÄ‚îÄ analysis.ipynb               # An√°lisis con pandas
‚îú‚îÄ‚îÄ docker-compose.yml           # PostgreSQL en Docker
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ extractions/
‚îÇ       ‚îî‚îÄ‚îÄ amazon/
‚îÇ           ‚îú‚îÄ‚îÄ amazon_cafe.json              ‚Üí Tabla: amazon_cafe
‚îÇ           ‚îú‚îÄ‚îÄ amazon_leche_de_vaca.json     ‚Üí Tabla: amazon_leche_de_vaca
‚îÇ           ‚îî‚îÄ‚îÄ amazon_monitor_gaming.json    ‚Üí Tabla: amazon_monitor_gaming
‚îî‚îÄ‚îÄ templates/
    ‚îî‚îÄ‚îÄ sql_query.html           # UI del frontend

```

## üîß Instalaci√≥n

```bash
# Instalar dependencias
uv pip install playwright pandas psycopg2-binary sqlalchemy flask

# Instalar navegadores de Playwright
playwright install

# Levantar PostgreSQL
docker-compose up -d
```

## üìä Uso

### Modo Integrado (Recomendado) üåü

```bash
# 1. Levantar PostgreSQL
docker-compose up -d

# 2. Iniciar frontend
python sql_frontend.py
```

Abre http://localhost:5000 y:

1. **Introduce t√©rmino de b√∫squeda** (ej: "auriculares gaming")
2. **Click en "üöÄ Iniciar Scraping"**
3. **Espera 5-10 minutos** (puedes usar SQL mientras tanto)
4. **La nueva tabla aparece autom√°ticamente** en el panel derecho
5. **¬°Consulta tus datos con SQL!**

### Modo Manual (Opcional)

#### 1. Scraping de productos

```bash
python main.py
# O con argumento: python main.py "cafe organico"
```

El script extraer√° los 50 productos mejor valorados.

#### 2. Cargar datos a PostgreSQL

```bash
python load_dynamic_tables.py
```

Este script:
- Lee todos los archivos JSON en `data/extractions/amazon/`
- Crea una tabla por cada archivo JSON
- Las columnas se infieren autom√°ticamente de las claves JSON
- Los datos anidados (objetos/arrays) se almacenan como JSONB

#### 3. Frontend SQL

```bash
python sql_frontend.py
```

Abre http://localhost:5000

## üéØ Interfaz del Frontend

### Panel Superior: Scraper Integrado
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ üîç Scraper de Amazon                                    ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ ‚îÇ cafe descafeinado               ‚îÇ üöÄ Iniciar      ‚îÇ ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ üîÑ Scraping iniciado... Visitando 50 productos        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Panel Izquierdo: Consultas de Ejemplo
- Ver todos los caf√©s
- Ver toda la leche
- Caf√© con Prime
- Top 5 mejor valorados
- Productos con descuento
- etc.

### Panel Central: Editor SQL
- Escribe consultas personalizadas
- Ejecuta con Ctrl+Enter
- Resultados en tabla interactiva

### Panel Derecho: Tablas Disponibles
- Lista de todas las tablas
- Click para ver esquema completo
- Se actualiza autom√°ticamente

## üìã Ejemplos de Tablas Creadas

**Ejemplos actuales:**
- `amazon_cafe.json` ‚Üí tabla `amazon_cafe` (50 productos)
- `amazon_leche_de_vaca.json` ‚Üí tabla `amazon_leche_de_vaca` (50 productos)
- `amazon_monitor_gaming.json` ‚Üí tabla `amazon_monitor_gaming` (50 productos)

**Despu√©s de buscar "teclado mecanico":**
- `amazon_teclado_mecanico.json` ‚Üí tabla `amazon_teclado_mecanico` (50 productos)
- Ver todas las tablas disponibles con sus esquemas
- Ejecutar consultas SQL personalizadas
- Usar consultas de ejemplo predefinidas
- Explorar datos con campos JSONB

## üóÑÔ∏è Esquema de Base de Datos (Din√°mico)

Cada tabla se crea autom√°ticamente con:

**Columnas b√°sicas** (inferidas del JSON):
- `id` (SERIAL PRIMARY KEY)
- `title` (TEXT)
- `brand` (TEXT)
- `price` (TEXT)
- `rating` (TEXT)
- `has_prime` (BOOLEAN)
- `created_at` (TIMESTAMP)

**Columnas JSONB** (para datos anidados):
- `specifications` (JSONB) - Especificaciones t√©cnicas
- `nutrition_facts` (JSONB) - Informaci√≥n nutricional
- `features` (JSONB) - Caracter√≠sticas del producto
- `product_overview` (JSONB) - Vista general del producto
- `options` (JSONB) - Variantes del producto

## üí° Ejemplos de Consultas SQL

```sql
-- Ver todos los caf√©s
SELECT id, title, brand, price, rating FROM amazon_cafe LIMIT 10;

-- Productos con Prime
SELECT title, brand, price, rating 
FROM amazon_cafe 
WHERE has_prime = true;

-- Extraer informaci√≥n nutricional (JSONB)
SELECT 
    title, 
    brand, 
    nutrition_facts->>'Energ√≠a' as energia,
    nutrition_facts->>'Prote√≠na' as proteina
FROM amazon_leche_de_vaca
WHERE nutrition_facts IS NOT NULL;

-- Consultar especificaciones t√©cnicas (JSONB)
SELECT 
    title,
    brand,
    specifications->>'Tama√±o de la pantalla' as pantalla,
    specifications->>'Frecuencia de actualizaci√≥n' as hz
FROM amazon_monitor_gaming
WHERE specifications IS NOT NULL;

-- Uni√≥n de todas las categor√≠as
SELECT 'Caf√©' as categoria, COUNT(*) FROM amazon_cafe
UNION ALL
SELECT 'Leche', COUNT(*) FROM amazon_leche_de_vaca
UNION ALL  
SELECT 'Monitor', COUNT(*) FROM amazon_monitor_gaming;
```

## üéØ Ventajas del Enfoque Din√°mico

1. **Todo desde el navegador**: No necesitas terminal, todo en http://localhost:5000
2. **Sin esquema fijo**: Cada JSON puede tener estructura diferente
3. **Autom√°tico**: No necesitas definir columnas manualmente
4. **Flexible**: Datos anidados en JSONB consultables con operadores JSON
5. **Escalable**: Agrega nuevos t√©rminos de b√∫squeda y autom√°ticamente se crean tablas
6. **Tiempo real**: Ve el progreso y usa SQL mientras el scraping corre en background

## üêõ Troubleshooting

- **Puerto ocupado**: PostgreSQL usa puerto 5434 (no 5432)
- **Error de conexi√≥n**: Verifica que Docker est√© corriendo: `docker ps`
- **Tablas vac√≠as**: Ejecuta primero `python load_dynamic_tables.py`

## üìù Notas T√©cnicas

- Los datos anidados (dict/list) se convierten a tipo JSONB
- Los nombres de columnas se limpian (sin espacios ni caracteres especiales)
- Las tablas se recrean cada vez que ejecutas `load_dynamic_tables.py`
- Frontend usa RealDictCursor para retornar resultados como diccionarios
